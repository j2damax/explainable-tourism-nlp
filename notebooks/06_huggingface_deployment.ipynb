{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VEs4IV6N9Zh"
      },
      "source": [
        "# Hugging Face Model Deployment\n",
        "\n",
        "This notebook provides a comprehensive pipeline for downloading the best performing model artifacts from MLflow and preparing them for deployment on Hugging Face Hub.\n",
        "\n",
        "## üéØ Overview\n",
        "- **Objective**: Download and prepare the best BERT model for Hugging Face deployment\n",
        "- **MLflow Run ID**: `ff204ab808384e77a8b1e40f56a3fd2a` (BERT-base-uncased, batch size 8)\n",
        "- **Model Performance**: 92.50% F1-Score, 92.33% Accuracy\n",
        "- **Target Platform**: Hugging Face Hub for public model sharing\n",
        "\n",
        "## üìã Features\n",
        "- ‚úÖ **Environment Detection**: Automatically detects Google Colab vs local environment\n",
        "- ‚úÖ **Configuration Management**: Centralized configuration with validation\n",
        "- ‚úÖ **Error Handling**: Comprehensive error handling and validation\n",
        "- ‚úÖ **Model Testing**: Built-in model testing with sample texts\n",
        "- ‚úÖ **Multiple Upload Methods**: API and manual git upload options\n",
        "- ‚úÖ **Usage Examples**: Production-ready code examples\n",
        "- ‚úÖ **Documentation**: Auto-generated README and model card\n",
        "\n",
        "## üöÄ Quick Start\n",
        "1. **Configure**: Update the configuration parameters in Cell 2\n",
        "2. **Setup**: Run all cells to prepare the model\n",
        "3. **Upload**: Uncomment and run the upload function\n",
        "4. **Deploy**: Your model will be available on Hugging Face Hub\n",
        "\n",
        "## üìÅ Output Files\n",
        "- `config.json`: Model configuration\n",
        "- `README.md`: Model documentation and usage examples\n",
        "- `pytorch_model.bin`: Model weights\n",
        "- `tokenizer.json`: Tokenizer configuration\n",
        "- `tokenizer_config.json`: Tokenizer settings\n",
        "\n",
        "## üîß Requirements\n",
        "- MLflow access (Databricks or local)\n",
        "- Hugging Face account and token\n",
        "- Python 3.8+ with required packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjK-4i5NN9Zj"
      },
      "source": [
        "## 1. Configuration and Setup\n",
        "\n",
        "### Configuration Parameters\n",
        "Configure these parameters based on your environment and requirements:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCQJzeYVN9Zj"
      },
      "outputs": [],
      "source": [
        "# Configuration Parameters\n",
        "# ========================\n",
        "\n",
        "# MLflow Configuration\n",
        "BEST_RUN_ID = \"ff204ab808384e77a8b1e40f56a3fd2a\"  # Update with your best model run ID\n",
        "MLFLOW_TRACKING_URI = \"databricks\"  # Options: \"databricks\", \"file:./mlruns\", or your custom URI\n",
        "\n",
        "# Model Configuration\n",
        "MODEL_NAME = \"bert-base-uncased\"  # Base model name\n",
        "NUM_LABELS = 4\n",
        "LABELS = [\n",
        "    \"Regenerative & Eco-Tourism\",\n",
        "    \"Integrated Wellness\", \n",
        "    \"Immersive Culinary\",\n",
        "    \"Off-the-Beaten-Path Adventure\"\n",
        "]\n",
        "\n",
        "# Path Configuration\n",
        "BASE_PATH = \"/content/drive/MyDrive/SerendipTravel\"  # Update for your environment\n",
        "MODEL_ARTIFACTS_PATH = f\"{BASE_PATH}/model_artifacts\"\n",
        "HF_MODEL_PATH = f\"{BASE_PATH}/model_artifacts/hf_model\"\n",
        "\n",
        "# Hugging Face Configuration\n",
        "HF_MODEL_NAME = \"your-username/serendip-travel-classifier\"  # Update with your HF username\n",
        "HF_REPO_TYPE = \"model\"\n",
        "HF_PRIVATE = False\n",
        "\n",
        "# Environment Detection\n",
        "IS_COLAB = False  # Set to True if running in Google Colab\n",
        "\n",
        "print(\"‚úÖ Configuration loaded successfully!\")\n",
        "print(f\"üìä Target Run ID: {BEST_RUN_ID}\")\n",
        "print(f\"üè∑Ô∏è  Model Name: {HF_MODEL_NAME}\")\n",
        "print(f\"üìÅ Base Path: {BASE_PATH}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8omk1gPCOeTG"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install mlflow huggingface_hub transformers torch databricks-sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility Functions\n",
        "# =================\n",
        "\n",
        "def validate_configuration():\n",
        "    \"\"\"Validate all configuration parameters\"\"\"\n",
        "    errors = []\n",
        "    warnings = []\n",
        "    \n",
        "    # Check required parameters\n",
        "    if not BEST_RUN_ID or BEST_RUN_ID == \"your-run-id\":\n",
        "        errors.append(\"BEST_RUN_ID not configured\")\n",
        "    \n",
        "    if HF_MODEL_NAME == \"your-username/serendip-travel-classifier\":\n",
        "        warnings.append(\"HF_MODEL_NAME not updated - using placeholder\")\n",
        "    \n",
        "    if not os.path.exists(BASE_PATH) and not IS_COLAB:\n",
        "        warnings.append(f\"BASE_PATH does not exist: {BASE_PATH}\")\n",
        "    \n",
        "    # Check MLflow connection\n",
        "    try:\n",
        "        mlflow.search_experiments(max_results=1)\n",
        "    except:\n",
        "        warnings.append(\"MLflow connection not available\")\n",
        "    \n",
        "    # Print results\n",
        "    if errors:\n",
        "        print(\"‚ùå Configuration Errors:\")\n",
        "        for error in errors:\n",
        "            print(f\"  - {error}\")\n",
        "    \n",
        "    if warnings:\n",
        "        print(\"‚ö†Ô∏è  Configuration Warnings:\")\n",
        "        for warning in warnings:\n",
        "            print(f\"  - {warning}\")\n",
        "    \n",
        "    if not errors and not warnings:\n",
        "        print(\"‚úÖ Configuration validation passed!\")\n",
        "    \n",
        "    return len(errors) == 0\n",
        "\n",
        "def print_configuration():\n",
        "    \"\"\"Print current configuration for review\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üìã CURRENT CONFIGURATION\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"MLflow Run ID: {BEST_RUN_ID}\")\n",
        "    print(f\"MLflow URI: {MLFLOW_TRACKING_URI}\")\n",
        "    print(f\"Model Name: {MODEL_NAME}\")\n",
        "    print(f\"HF Model Name: {HF_MODEL_NAME}\")\n",
        "    print(f\"Base Path: {BASE_PATH}\")\n",
        "    print(f\"Model Artifacts Path: {MODEL_ARTIFACTS_PATH}\")\n",
        "    print(f\"HF Model Path: {HF_MODEL_PATH}\")\n",
        "    print(f\"Is Colab: {IS_COLAB}\")\n",
        "    print(f\"Labels: {LABELS}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# Validate configuration\n",
        "validate_configuration()\n",
        "print_configuration()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQdq3QdrN9Zk",
        "outputId": "ae7eb107-5557-461b-984e-b694cd69e5a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully\n",
            "PyTorch version: 2.8.0+cu126\n",
            "MLflow version: 3.4.0\n"
          ]
        }
      ],
      "source": [
        "# Import Required Libraries\n",
        "# =========================\n",
        "\n",
        "# Standard library imports\n",
        "import os\n",
        "import json\n",
        "import warnings\n",
        "\n",
        "# Third-party imports\n",
        "import torch\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Transformers imports\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification\n",
        ")\n",
        "\n",
        "# Hugging Face Hub imports\n",
        "from huggingface_hub import HfApi, create_repo\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Version information\n",
        "print(\"üì¶ Libraries imported successfully\")\n",
        "print(f\"  PyTorch: {torch.__version__}\")\n",
        "print(f\"  MLflow: {mlflow.__version__}\")\n",
        "\n",
        "# Check for optional dependencies\n",
        "try:\n",
        "    from huggingface_hub import whoami\n",
        "    print(\"  Hugging Face Hub: ‚úÖ Available\")\n",
        "except ImportError:\n",
        "    print(\"  Hugging Face Hub: ‚ùå Not available\")\n",
        "\n",
        "try:\n",
        "    import mlflow\n",
        "    print(\"  MLflow: ‚úÖ Available\")\n",
        "except ImportError:\n",
        "    print(\"  MLflow: ‚ùå Not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXQ9PXbzPALZ",
        "outputId": "6576ba35-821a-4504-b250-0bd23a8c3779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Colab environment detected\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup and Validation\n",
        "# =================================\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Setup environment variables and detect runtime environment\"\"\"\n",
        "    global IS_COLAB, BASE_PATH, MODEL_ARTIFACTS_PATH, HF_MODEL_PATH\n",
        "    \n",
        "    # Load environment variables\n",
        "    load_dotenv()\n",
        "    \n",
        "    # Detect environment\n",
        "    try:\n",
        "        from google.colab import drive, userdata\n",
        "        IS_COLAB = True\n",
        "        print(\"üü¢ Google Colab environment detected\")\n",
        "        \n",
        "        # Mount drive if not already mounted\n",
        "        try:\n",
        "            drive.mount('/content/drive', force_remount=False)\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è  Drive already mounted or mounting failed\")\n",
        "            \n",
        "        # Get Databricks credentials from Colab secrets\n",
        "        DATABRICKS_HOST = userdata.get(\"DATABRICKS_HOST\")\n",
        "        DATABRICKS_TOKEN = userdata.get(\"DATABRICKS_TOKEN\")\n",
        "        \n",
        "    except ImportError:\n",
        "        IS_COLAB = False\n",
        "        print(\"üü¢ Local environment detected\")\n",
        "        \n",
        "        # Get Databricks credentials from environment variables\n",
        "        DATABRICKS_HOST = os.getenv(\"DATABRICKS_HOST\")\n",
        "        DATABRICKS_TOKEN = os.getenv(\"DATABRICKS_TOKEN\")\n",
        "        \n",
        "        # Update paths for local environment\n",
        "        BASE_PATH = os.path.join(os.getcwd(), \"model_artifacts\")\n",
        "        MODEL_ARTIFACTS_PATH = BASE_PATH\n",
        "        HF_MODEL_PATH = os.path.join(BASE_PATH, \"hf_model\")\n",
        "    \n",
        "    # Set Databricks environment variables\n",
        "    if DATABRICKS_HOST and DATABRICKS_TOKEN:\n",
        "        os.environ[\"DATABRICKS_HOST\"] = DATABRICKS_HOST\n",
        "        os.environ[\"DATABRICKS_TOKEN\"] = DATABRICKS_TOKEN\n",
        "        print(\"‚úÖ Databricks credentials configured\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Databricks credentials not found - will use local MLflow\")\n",
        "    \n",
        "    # Create directories\n",
        "    os.makedirs(MODEL_ARTIFACTS_PATH, exist_ok=True)\n",
        "    os.makedirs(HF_MODEL_PATH, exist_ok=True)\n",
        "    \n",
        "    print(f\"üìÅ Model artifacts path: {MODEL_ARTIFACTS_PATH}\")\n",
        "    print(f\"üìÅ HF model path: {HF_MODEL_PATH}\")\n",
        "    \n",
        "    return True\n",
        "\n",
        "# Setup environment\n",
        "setup_environment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVVakCgbN9Zk"
      },
      "source": [
        "## 2. MLflow Configuration and Model Download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekrl2CbEN9Zk",
        "outputId": "9998eea6-6b5c-4203-96ab-a751e238c419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to Databricks MLflow\n",
            "Target MLflow Run ID: ff204ab808384e77a8b1e40f56a3fd2a\n"
          ]
        }
      ],
      "source": [
        "# MLflow Configuration\n",
        "# ===================\n",
        "\n",
        "def setup_mlflow():\n",
        "    \"\"\"Setup MLflow tracking URI with fallback options\"\"\"\n",
        "    try:\n",
        "        if MLFLOW_TRACKING_URI == \"databricks\":\n",
        "            # Try Databricks first\n",
        "            mlflow.set_tracking_uri(\"databricks\")\n",
        "            print(\"‚úÖ Connected to Databricks MLflow\")\n",
        "        else:\n",
        "            # Use specified URI\n",
        "            mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "            print(f\"‚úÖ Connected to MLflow at: {MLFLOW_TRACKING_URI}\")\n",
        "            \n",
        "        # Test connection\n",
        "        mlflow.search_experiments(max_results=1)\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Failed to connect to {MLFLOW_TRACKING_URI}: {e}\")\n",
        "        \n",
        "        # Fallback to local\n",
        "        try:\n",
        "            mlflow.set_tracking_uri(\"file:./mlruns\")\n",
        "            print(\"‚úÖ Fallback: Using local MLflow tracking\")\n",
        "            return True\n",
        "        except Exception as e2:\n",
        "            print(f\"‚ùå Failed to setup local MLflow: {e2}\")\n",
        "            return False\n",
        "\n",
        "# Setup MLflow\n",
        "if setup_mlflow():\n",
        "    print(f\"üìä Target MLflow Run ID: {BEST_RUN_ID}\")\n",
        "else:\n",
        "    print(\"‚ùå MLflow setup failed - please check your configuration\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "79c18ad732224584ba3ec447c1476f8d",
            "c86da99fa0cc421fb2467473beb33f99",
            "b8e884518bab401c9991b8832563324d",
            "b44cb092f84d4b9196f422d626240fa6",
            "578df85147bc40c3855fb6ede8efc242",
            "6763d6b29bb2482eb14fdd078462f668",
            "f9059503f2684e9986bcd452fe34c68f",
            "3f11fd66706e4845a9ea69b10402757e",
            "0c2a430228f14cb6978e78aad56283b0",
            "7903d848fb54474685d77d1a20717610",
            "9ab8e339a92f4700a3ad6177863d46e2",
            "059159dfffb8454da5c85d9649a0b613",
            "ac028af2cb6141898bd9b8947f809a52",
            "fa919897ae544c0e90d5a0d1a39b0c57",
            "7f49722f8afc4941a254bae3d09fa089",
            "119fb99cf8ac4f7fb72e04ea80e16c55",
            "21539f3c4e814de49d514b1c8bd36111",
            "641fd6e02d86455c8aa36f42a7d3c57d",
            "b231df5bdece4fe195749704707811f8",
            "7898328708fa46118bd60a37d3fd21cf",
            "0e52838fe9574d6e8eb9e9044a051dc5",
            "7e29b7f4260d41e4919618519f4c19ca"
          ]
        },
        "id": "QdnwxUzCN9Zl",
        "outputId": "a9737205-54ef-47e4-b786-dd1a74c0d5b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading model from: runs:/ff204ab808384e77a8b1e40f56a3fd2a/model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79c18ad732224584ba3ec447c1476f8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "059159dfffb8454da5c85d9649a0b613",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model downloaded successfully to: /content/drive/MyDrive/SerendipTravel/model_artifacts\n"
          ]
        }
      ],
      "source": [
        "# Model Download from MLflow\n",
        "# ==========================\n",
        "\n",
        "def download_mlflow_model(run_id, download_path=None):\n",
        "    \"\"\"Download model artifacts from MLflow run with validation\"\"\"\n",
        "    if download_path is None:\n",
        "        download_path = MODEL_ARTIFACTS_PATH\n",
        "        \n",
        "    try:\n",
        "        # Validate run_id\n",
        "        if not run_id or not isinstance(run_id, str):\n",
        "            raise ValueError(\"Invalid run_id provided\")\n",
        "            \n",
        "        # Create download directory\n",
        "        os.makedirs(download_path, exist_ok=True)\n",
        "        print(f\"üìÅ Download directory: {download_path}\")\n",
        "\n",
        "        # Check if run exists\n",
        "        try:\n",
        "            run = mlflow.get_run(run_id)\n",
        "            print(f\"‚úÖ Found MLflow run: {run_id}\")\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"MLflow run {run_id} not found: {e}\")\n",
        "\n",
        "        # Download the model\n",
        "        model_uri = f\"runs:/{run_id}/model\"\n",
        "        print(f\"‚¨áÔ∏è  Downloading model from: {model_uri}\")\n",
        "\n",
        "        # Download model artifacts\n",
        "        model = mlflow.pytorch.load_model(model_uri, dst_path=download_path)\n",
        "\n",
        "        print(f\"‚úÖ Model downloaded successfully to: {download_path}\")\n",
        "        \n",
        "        # List downloaded files\n",
        "        if os.path.exists(download_path):\n",
        "            files = os.listdir(download_path)\n",
        "            print(f\"üìÑ Downloaded files: {files}\")\n",
        "        \n",
        "        return download_path, model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error downloading model: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Download the best model\n",
        "model_path, downloaded_model = download_mlflow_model(BEST_RUN_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1wjtcj4N9Zl",
        "outputId": "4f531a83-7fe9-4545-b9cd-62e301b1f7b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MLFLOW RUN INFORMATION\n",
            "============================================================\n",
            "Run ID: ff204ab808384e77a8b1e40f56a3fd2a\n",
            "Run Name: bert-base-uncased-lr2e-05-bs8\n",
            "Status: FINISHED\n",
            "Start Time: 1758728157353\n",
            "End Time: 1758728590008\n",
            "\n",
            "Parameters:\n",
            "  batch_size: 8\n",
            "  epochs: 5\n",
            "  learning_rate: 2e-05\n",
            "  model_name: bert-base-uncased\n",
            "\n",
            "Metrics:\n",
            "  f1_label_0: 0.9178617992177314\n",
            "  f1_label_1: 0.9142857142857143\n",
            "  f1_label_2: 0.9111570247933884\n",
            "  f1_label_3: 0.9565929565929566\n",
            "  precision_label_0: 0.9630642954856361\n",
            "  precision_label_1: 0.9808429118773946\n",
            "  precision_label_2: 0.9504310344827587\n",
            "  precision_label_3: 0.9782244556113903\n",
            "  recall_label_0: 0.8767123287671232\n",
            "  recall_label_1: 0.8561872909698997\n",
            "  recall_label_2: 0.875\n",
            "  recall_label_3: 0.9358974358974359\n",
            "  test_accuracy: 0.9232673267326733\n",
            "  test_f1: 0.9249743737224476\n",
            "  test_precision: 0.9681406743642949\n",
            "  test_recall: 0.8859492639086146\n",
            "  train_loss: 0.025108116490579372\n",
            "  val_accuracy: 0.9156999226604795\n",
            "  val_f1: 0.9221403795505014\n",
            "  val_loss: 0.08627338893424122\n",
            "\n",
            "Tags:\n",
            "  mlflow.note.content: Best performing model\n",
            "  mlflow.runColor: #a46750\n",
            "  mlflow.runName: bert-base-uncased-lr2e-05-bs8\n",
            "  mlflow.source.name: /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\n",
            "  mlflow.source.type: LOCAL\n",
            "  mlflow.user: j2damax@gmail.com\n"
          ]
        }
      ],
      "source": [
        "# Get run information and metrics\n",
        "def get_run_info(run_id):\n",
        "    \"\"\"Get detailed information about the MLflow run\"\"\"\n",
        "    try:\n",
        "        # Get run details\n",
        "        run = mlflow.get_run(run_id)\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"MLFLOW RUN INFORMATION\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Run ID: {run_id}\")\n",
        "        print(f\"Run Name: {run.data.tags.get('mlflow.runName', 'N/A')}\")\n",
        "        print(f\"Status: {run.info.status}\")\n",
        "        print(f\"Start Time: {run.info.start_time}\")\n",
        "        print(f\"End Time: {run.info.end_time}\")\n",
        "\n",
        "        print(f\"\\nParameters:\")\n",
        "        for key, value in run.data.params.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "        print(f\"\\nMetrics:\")\n",
        "        for key, value in run.data.metrics.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "        print(f\"\\nTags:\")\n",
        "        for key, value in run.data.tags.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "        return run\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting run info: {e}\")\n",
        "        return None\n",
        "\n",
        "# Get run information\n",
        "run_info = get_run_info(BEST_RUN_ID)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nKeI65fN9Zl"
      },
      "source": [
        "## 3. Model Preparation for Hugging Face\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "530ef99640bc4cb6b3936a05efc18806",
            "bf547badfa7a4275a9c82c895cce723d",
            "1b89ef2c2ca5423a85782ccbd10269e6",
            "841d4f15e9d64f788e64d616558d312f",
            "36e9a01f4774408baa7cef8ee497cf95",
            "db0b93c98cdb43afbd0d38fa4c60f8b6",
            "497094dab6bd4b749563f033aa06af2c",
            "0666650edd274bd4845382e2cd840f59",
            "3089c4ea1a534a2ba8bd2d0d3156c8fa",
            "122cb4ec9e2d4df7bb1d49fbbbb9938a",
            "c5dc0fe4efc54ab79aba9ee9907aba9c",
            "31b7994ee99b4bc18e7ec4ba4c525a1f",
            "608ed9edf9ee4f1cb59ccc473d3cabc6",
            "23dc88340108406c832e59946457e634",
            "3398b12db41f424b9a95cbdff93c6801",
            "ec71b9b9644844ecb4283692037f9362",
            "7805b4cd8f414b22b144f967977056aa",
            "320ded16b2d341a7a98bc4ef3c8409e4",
            "8c7c460aea644e4ab9865f43b8b4d23c",
            "1e05c92228e848eba05410138b8be299",
            "6395f67e16504e0d87873a115b472914",
            "5f92ab6d3b6447c2907316c6d9ceae56"
          ]
        },
        "id": "pqlEqrQjN9Zl",
        "outputId": "08c45f0b-9e1b-401f-dd6a-be761e8ca2b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from MLflow...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "530ef99640bc4cb6b3936a05efc18806",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31b7994ee99b4bc18e7ec4ba4c525a1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading tokenizer...\n",
            "Saving model to /content/drive/MyDrive/SerendipTravel/model_artifacts/hf_model...\n",
            "Model and tokenizer saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Model Preparation for Hugging Face\n",
        "# ==================================\n",
        "\n",
        "def prepare_model_for_hf(model_path=None, hf_model_path=None):\n",
        "    \"\"\"Prepare the MLflow model for Hugging Face Hub with validation\"\"\"\n",
        "    if model_path is None:\n",
        "        model_path = MODEL_ARTIFACTS_PATH\n",
        "    if hf_model_path is None:\n",
        "        hf_model_path = HF_MODEL_PATH\n",
        "        \n",
        "    try:\n",
        "        # Validate inputs\n",
        "        if not model_path or not os.path.exists(model_path):\n",
        "            raise ValueError(f\"Model path does not exist: {model_path}\")\n",
        "            \n",
        "        # Create Hugging Face model directory\n",
        "        os.makedirs(hf_model_path, exist_ok=True)\n",
        "        print(f\"üìÅ HF model directory: {hf_model_path}\")\n",
        "\n",
        "        # Load the model from MLflow\n",
        "        print(\"üîÑ Loading model from MLflow...\")\n",
        "        model_uri = f\"runs:/{BEST_RUN_ID}/model\"\n",
        "        model = mlflow.pytorch.load_model(model_uri)\n",
        "\n",
        "        # Load the tokenizer\n",
        "        print(\"üîÑ Loading tokenizer...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "        # Save model and tokenizer in Hugging Face format\n",
        "        print(f\"üíæ Saving model to {hf_model_path}...\")\n",
        "        model.save_pretrained(hf_model_path)\n",
        "        tokenizer.save_pretrained(hf_model_path)\n",
        "\n",
        "        print(\"‚úÖ Model and tokenizer saved successfully!\")\n",
        "        \n",
        "        # Verify saved files\n",
        "        if os.path.exists(hf_model_path):\n",
        "            files = os.listdir(hf_model_path)\n",
        "            print(f\"üìÑ Saved files: {files}\")\n",
        "        \n",
        "        return hf_model_path, model, tokenizer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error preparing model: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# Prepare the model\n",
        "if model_path:\n",
        "    hf_path, model, tokenizer = prepare_model_for_hf(model_path)\n",
        "else:\n",
        "    print(\"‚ùå Cannot prepare model - download failed\")\n",
        "    hf_path, model, tokenizer = None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Da3-wY8ON9Zl",
        "outputId": "c785577e-0387-422b-c172-c57d72562777"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-3591915975.py, line 42)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3591915975.py\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    readme_content = f\"\"\"---\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "# Create model configuration and metadata\n",
        "def create_model_config(hf_path, run_info):\n",
        "    \"\"\"Create configuration files for Hugging Face model\"\"\"\n",
        "    try:\n",
        "        # Model configuration\n",
        "        config = {\n",
        "            \"model_type\": \"bert\",\n",
        "            \"architectures\": [\"BertForSequenceClassification\"],\n",
        "            \"num_labels\": 4,\n",
        "            \"id2label\": {\n",
        "                \"0\": \"Regenerative & Eco-Tourism\",\n",
        "                \"1\": \"Integrated Wellness\",\n",
        "                \"2\": \"Immersive Culinary\",\n",
        "                \"3\": \"Off-the-Beaten-Path Adventure\"\n",
        "            },\n",
        "            \"label2id\": {\n",
        "                \"Regenerative & Eco-Tourism\": 0,\n",
        "                \"Integrated Wellness\": 1,\n",
        "                \"Immersive Culinary\": 2,\n",
        "                \"Off-the-Beaten-Path Adventure\": 3\n",
        "            },\n",
        "            \"problem_type\": \"multi_label_classification\"\n",
        "        }\n",
        "\n",
        "        # Save config.json\n",
        "        with open(f\"{hf_path}/config.json\", \"w\") as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        # Extract metrics from run_info\n",
        "        metrics = run_info.data.metrics if run_info and run_info.data else {}\n",
        "        f1_score = metrics.get('test_f1', 'N/A')\n",
        "        accuracy = metrics.get('test_accuracy', 'N/A')\n",
        "        precision = metrics.get('test_precision', 'N/A')\n",
        "        recall = metrics.get('test_recall', 'N/A')\n",
        "        model_name_param = run_info.data.params.get('model_name', 'BERT model') if run_info and run_info.data else 'BERT model'\n",
        "        batch_size = run_info.data.params.get('batch_size', 'N/A') if run_info and run_info.data else 'N/A'\n",
        "        learning_rate = run_info.data.params.get('learning_rate', 'N/A') if run_info and run_info.data else 'N/A'\n",
        "        epochs = run_info.data.params.get('epochs', 'N/A') if run_info and run_info.data else 'N/A'\n",
        "\n",
        "        # Create README.md\n",
        "        readme_content = f\"\"\"---\n",
        "language: en\n",
        "license: mit\n",
        "tags:\n",
        "- text-classification\n",
        "- multi-label\n",
        "- tourism\n",
        "- sri-lanka\n",
        "- bert\n",
        "- pytorch\n",
        "datasets:\n",
        "- tourism-reviews-sri-lanka\n",
        "metrics:\n",
        "- f1\n",
        "- accuracy\n",
        "- precision\n",
        "- recall\n",
        "model-index:\n",
        "- name: serendip-travel-experiential-classifier\n",
        "  results:\n",
        "  - task:\n",
        "      type: text-classification\n",
        "      name: Multi-Label Text Classification\n",
        "    dataset:\n",
        "      type: tourism-reviews-sri-lanka\n",
        "      name: Sri Lankan Tourism Reviews\n",
        "    metrics:\n",
        "    - type: f1\n",
        "      value: {f1_score if isinstance(f1_score, (int, float)) else 'N/A':.4f}\n",
        "    - type: accuracy\n",
        "      value: {accuracy if isinstance(accuracy, (int, float)) else 'N/A':.4f}\n",
        "    - type: precision\n",
        "      value: {precision if isinstance(precision, (int, float)) else 'N/A':.4f}\n",
        "    - type: recall\n",
        "      value: {recall if isinstance(recall, (int, float)) else 'N/A':.4f}\n",
        "---\n",
        "\n",
        "# Serendip Travel Experiential Classifier\n",
        "\n",
        "A fine-tuned {model_name_param} model for classifying Sri Lankan tourist reviews into four experiential dimensions.\n",
        "\n",
        "## Model Description\n",
        "\n",
        "This model is a fine-tuned {model_name_param} model trained on Sri Lankan tourism reviews to classify text into four experiential dimensions:\n",
        "\n",
        "1. **Regenerative & Eco-Tourism**: Travel focused on positive social and environmental impact\n",
        "2. **Integrated Wellness**: Journeys combining physical and mental well-being\n",
        "3. **Immersive Culinary**: Experiences centered on authentic local cuisine\n",
        "4. **Off-the-Beaten-Path Adventure**: Exploration of less crowded natural landscapes\n",
        "\n",
        "## Performance\n",
        "\n",
        "- **F1-Score**: {f1_score if isinstance(f1_score, (int, float)) else 'N/A':.4f}\n",
        "- **Accuracy**: {accuracy if isinstance(accuracy, (int, float)) else 'N/A':.4f}\n",
        "- **Precision**: {precision if isinstance(precision, (int, float)) else 'N/A':.4f}\n",
        "- **Recall**: {recall if isinstance(recall, (int, float)) else 'N/A':.4f}\n",
        "\n",
        "## Training Details\n",
        "\n",
        "- **Model**: {model_name_param}\n",
        "- **Batch Size**: {batch_size}\n",
        "- **Learning Rate**: {learning_rate}\n",
        "- **Epochs**: {epochs}\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"your-username/serendip-travel-classifier\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"your-username/serendip-travel-classifier\")\n",
        "\n",
        "# Example text\n",
        "text = \"The organic tea plantation tour was amazing! We learned about sustainable farming practices.\"\n",
        "\n",
        "# Tokenize and predict\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.sigmoid(outputs.logits)\n",
        "\n",
        "# Get predicted labels\n",
        "labels = [\"Regenerative & Eco-Tourism\", \"Integrated Wellness\", \"Immersive Culinary\", \"Off-the-Beaten-Path Adventure\"]\n",
        "predicted_labels = [labels[i] for i, score in enumerate(predictions[0]) if score > 0.5]\n",
        "print(f\"Predicted labels: {predicted_labels}\")\n",
        "```\n",
        "\n",
        "## Model Card\n",
        "\n",
        "This model was trained on Sri Lankan tourism reviews to classify experiences into four categories. The model uses a multi-label classification approach, meaning a single review can be classified into multiple categories simultaneously.\n",
        "\n",
        "### Limitations\n",
        "\n",
        "- Trained specifically on Sri Lankan tourism data\n",
        "- May not generalize well to other geographical regions\n",
        "- Performance may vary with different text styles or languages\n",
        "\n",
        "### Citation\n",
        "\n",
        "If you use this model, please cite:\n",
        "\n",
        "```bibtex\n",
        "@misc{{serendip-travel-classifier,\n",
        "  title={{Serendip Travel Experiential Classifier}},\n",
        "  author={{Your Name}},\n",
        "  year={{2024}},\n",
        "  publisher={{Hugging Face}},\n",
        "  url={{https://huggingface.co/your-username/serendip-travel-classifier}}\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "        # Save README.md\n",
        "        with open(f\"{hf_path}/README.md\", \"w\") as f:\n",
        "            f.write(readme_content)\n",
        "\n",
        "        print(\"‚úÖ Configuration files created successfully!\")\n",
        "        print(f\"  - config.json\")\n",
        "        print(f\"  - README.md\")\n",
        "        \n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating model config: {e}\")\n",
        "        return False\n",
        "\n",
        "# Create model configuration\n",
        "if hf_path and run_info:\n",
        "    create_model_config(hf_path, run_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXzVbVMON9Zl"
      },
      "source": [
        "## 4. Model Testing and Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IOuK-xcN9Zm",
        "outputId": "247d290a-7d84-4701-b83d-1e9b7c6498c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MODEL TESTING\n",
            "============================================================\n",
            "\n",
            "Test 1: The organic tea plantation tour was amazing! We learned about sustainable farming practices and envi...\n",
            "Predicted labels:\n",
            "  ‚úì Regenerative & Eco-Tourism: 0.999\n",
            "  ‚úó Integrated Wellness: 0.005\n",
            "  ‚úó Immersive Culinary: 0.017\n",
            "  ‚úó Off-the-Beaten-Path Adventure: 0.006\n",
            "\n",
            "Test 2: The spa retreat offered incredible yoga sessions and meditation classes. Perfect for relaxation and ...\n",
            "Predicted labels:\n",
            "  ‚úó Regenerative & Eco-Tourism: 0.005\n",
            "  ‚úì Integrated Wellness: 0.995\n",
            "  ‚úó Immersive Culinary: 0.004\n",
            "  ‚úó Off-the-Beaten-Path Adventure: 0.006\n",
            "\n",
            "Test 3: The local cooking class was fantastic! We learned to make authentic Sri Lankan curry with fresh spic...\n",
            "Predicted labels:\n",
            "  ‚úì Regenerative & Eco-Tourism: 0.992\n",
            "  ‚úó Integrated Wellness: 0.007\n",
            "  ‚úì Immersive Culinary: 0.999\n",
            "  ‚úó Off-the-Beaten-Path Adventure: 0.013\n",
            "\n",
            "Test 4: The hiking trail through the remote jungle was challenging but rewarding. We saw amazing wildlife an...\n",
            "Predicted labels:\n",
            "  ‚úó Regenerative & Eco-Tourism: 0.005\n",
            "  ‚úó Integrated Wellness: 0.007\n",
            "  ‚úó Immersive Culinary: 0.010\n",
            "  ‚úì Off-the-Beaten-Path Adventure: 0.999\n"
          ]
        }
      ],
      "source": [
        "# Model Testing and Validation\n",
        "# ============================\n",
        "\n",
        "def test_model_prediction(model, tokenizer, test_texts=None, threshold=0.5):\n",
        "    \"\"\"Test the model with sample texts and validation\"\"\"\n",
        "    if test_texts is None:\n",
        "        test_texts = [\n",
        "            \"The organic tea plantation tour was amazing! We learned about sustainable farming practices and environmental conservation.\",\n",
        "            \"The spa retreat offered incredible yoga sessions and meditation classes. Perfect for relaxation and wellness.\",\n",
        "            \"The local cooking class was fantastic! We learned to make authentic Sri Lankan curry with fresh spices from the market.\",\n",
        "            \"The hiking trail through the remote jungle was challenging but rewarding. We saw amazing wildlife and untouched nature.\"\n",
        "        ]\n",
        "    \n",
        "    try:\n",
        "        # Validate inputs\n",
        "        if not model or not tokenizer:\n",
        "            raise ValueError(\"Model or tokenizer not provided\")\n",
        "            \n",
        "        print(\"=\" * 60)\n",
        "        print(\"üß™ MODEL TESTING\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Determine device\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "        print(f\"üñ•Ô∏è  Using device: {device}\")\n",
        "\n",
        "        results = []\n",
        "        for i, text in enumerate(test_texts, 1):\n",
        "            print(f\"\\nüìù Test {i}: {text[:100]}{'...' if len(text) > 100 else ''}\")\n",
        "\n",
        "            # Tokenize input and move to device\n",
        "            inputs = tokenizer(\n",
        "                text, \n",
        "                return_tensors=\"pt\", \n",
        "                truncation=True, \n",
        "                padding=True, \n",
        "                max_length=512\n",
        "            ).to(device)\n",
        "\n",
        "            # Get predictions\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                predictions = torch.sigmoid(outputs.logits)\n",
        "\n",
        "            # Display results\n",
        "            print(\"üè∑Ô∏è  Predicted labels:\")\n",
        "            test_result = {\"text\": text, \"predictions\": []}\n",
        "            \n",
        "            for j, (label, score) in enumerate(zip(LABELS, predictions[0])):\n",
        "                status = \"‚úÖ\" if score > threshold else \"‚ùå\"\n",
        "                print(f\"  {status} {label}: {score:.3f}\")\n",
        "                test_result[\"predictions\"].append({\n",
        "                    \"label\": label,\n",
        "                    \"score\": float(score),\n",
        "                    \"predicted\": score > threshold\n",
        "                })\n",
        "            \n",
        "            results.append(test_result)\n",
        "\n",
        "        print(f\"\\n‚úÖ Model testing completed successfully!\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error testing model: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test the model\n",
        "if model and tokenizer:\n",
        "    test_results = test_model_prediction(model, tokenizer)\n",
        "else:\n",
        "    print(\"‚ùå Cannot test model - model or tokenizer not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNdi10Y2N9Zm"
      },
      "source": [
        "## 5. Hugging Face Hub Upload\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLYm3c7xN9Zm"
      },
      "outputs": [],
      "source": [
        "# Hugging Face Hub Setup\n",
        "# =====================\n",
        "\n",
        "def setup_huggingface_upload():\n",
        "    \"\"\"Setup Hugging Face Hub for model upload with validation\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üöÄ HUGGING FACE HUB SETUP\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(\"üìã Prerequisites:\")\n",
        "    print(\"1. Create a Hugging Face account at https://huggingface.co/\")\n",
        "    print(\"2. Generate an access token at https://huggingface.co/settings/tokens\")\n",
        "    print(\"3. Install and login to huggingface_hub:\")\n",
        "    print(\"   !pip install huggingface_hub\")\n",
        "    print(\"   !huggingface-cli login\")\n",
        "    print(\"4. Update the HF_MODEL_NAME in the configuration cell\")\n",
        "\n",
        "    # Validate model name\n",
        "    if HF_MODEL_NAME == \"your-username/serendip-travel-classifier\":\n",
        "        print(f\"\\n‚ö†Ô∏è  WARNING: Please update HF_MODEL_NAME in the configuration!\")\n",
        "        print(\"   Current value: your-username/serendip-travel-classifier\")\n",
        "        print(\"   Expected format: your-username/model-name\")\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ Model name configured: {HF_MODEL_NAME}\")\n",
        "\n",
        "    # Check if logged in\n",
        "    try:\n",
        "        from huggingface_hub import whoami\n",
        "        user_info = whoami()\n",
        "        print(f\"‚úÖ Logged in as: {user_info['name']}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Not logged in to Hugging Face: {e}\")\n",
        "        print(\"   Please run: huggingface-cli login\")\n",
        "        return False\n",
        "\n",
        "# Setup Hugging Face\n",
        "hf_ready = setup_huggingface_upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAL-zCCyN9Zm"
      },
      "outputs": [],
      "source": [
        "# Upload Model to Hugging Face Hub\n",
        "# ================================\n",
        "\n",
        "def upload_to_huggingface(hf_path=None, model_name=None):\n",
        "    \"\"\"Upload the prepared model to Hugging Face Hub with validation\"\"\"\n",
        "    if hf_path is None:\n",
        "        hf_path = HF_MODEL_PATH\n",
        "    if model_name is None:\n",
        "        model_name = HF_MODEL_NAME\n",
        "        \n",
        "    try:\n",
        "        # Validate inputs\n",
        "        if not hf_path or not os.path.exists(hf_path):\n",
        "            raise ValueError(f\"HF model path does not exist: {hf_path}\")\n",
        "            \n",
        "        if model_name == \"your-username/serendip-travel-classifier\":\n",
        "            raise ValueError(\"Please update HF_MODEL_NAME in configuration\")\n",
        "            \n",
        "        print(\"=\" * 60)\n",
        "        print(\"üöÄ UPLOADING TO HUGGING FACE HUB\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Initialize Hugging Face API\n",
        "        api = HfApi()\n",
        "\n",
        "        # Create repository\n",
        "        print(f\"üìÅ Creating repository: {model_name}\")\n",
        "        create_repo(model_name, exist_ok=True, private=HF_PRIVATE)\n",
        "\n",
        "        # List files to upload\n",
        "        files_to_upload = os.listdir(hf_path)\n",
        "        print(f\"üìÑ Files to upload: {files_to_upload}\")\n",
        "\n",
        "        # Upload all files\n",
        "        print(f\"‚¨ÜÔ∏è  Uploading files from {hf_path}...\")\n",
        "        api.upload_folder(\n",
        "            folder_path=hf_path,\n",
        "            repo_id=model_name,\n",
        "            repo_type=HF_REPO_TYPE\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ Model successfully uploaded to: https://huggingface.co/{model_name}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error uploading to Hugging Face: {e}\")\n",
        "        print(\"\\nüîß Troubleshooting:\")\n",
        "        print(\"1. Make sure you're logged in: huggingface-cli login\")\n",
        "        print(\"2. Check your access token permissions\")\n",
        "        print(\"3. Verify the model name is correct\")\n",
        "        print(\"4. Ensure HF_MODEL_NAME is updated in configuration\")\n",
        "        return False\n",
        "\n",
        "# Upload the model (uncomment when ready)\n",
        "# if hf_ready and hf_path:\n",
        "#     upload_success = upload_to_huggingface(hf_path, HF_MODEL_NAME)\n",
        "# else:\n",
        "#     print(\"‚ùå Cannot upload - setup not complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KL1XaSeN9Zm"
      },
      "source": [
        "## 6. Alternative Upload Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcY4a33zN9Zm"
      },
      "outputs": [],
      "source": [
        "# Alternative Upload Methods\n",
        "# ==========================\n",
        "\n",
        "def create_git_upload_instructions(hf_path=None, model_name=None):\n",
        "    \"\"\"Create instructions for manual git upload with validation\"\"\"\n",
        "    if hf_path is None:\n",
        "        hf_path = HF_MODEL_PATH\n",
        "    if model_name is None:\n",
        "        model_name = HF_MODEL_NAME\n",
        "        \n",
        "    print(\"=\" * 60)\n",
        "    print(\"üîÑ ALTERNATIVE: MANUAL GIT UPLOAD\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(\"If the API upload fails, you can use git to upload manually:\")\n",
        "    print()\n",
        "    print(\"1. Clone the repository:\")\n",
        "    print(f\"   git clone https://huggingface.co/{model_name}\")\n",
        "    print()\n",
        "    print(\"2. Copy files to the repository:\")\n",
        "    print(f\"   cp -r {hf_path}/* {model_name.split('/')[-1]}/\")\n",
        "    print()\n",
        "    print(\"3. Add, commit, and push:\")\n",
        "    print(f\"   cd {model_name.split('/')[-1]}\")\n",
        "    print(\"   git add .\")\n",
        "    print(\"   git commit -m 'Add model files'\")\n",
        "    print(\"   git push\")\n",
        "    print()\n",
        "    print(\"4. Or use the web interface:\")\n",
        "    print(f\"   https://huggingface.co/{model_name}\")\n",
        "    print(\"   - Click 'Add file' -> 'Upload files'\")\n",
        "    print(f\"   - Upload all files from {hf_path}/\")\n",
        "\n",
        "    # List files to upload\n",
        "    print(f\"\\nüìÑ Files to upload from {hf_path}:\")\n",
        "    if os.path.exists(hf_path):\n",
        "        files = os.listdir(hf_path)\n",
        "        for file in files:\n",
        "            file_path = os.path.join(hf_path, file)\n",
        "            file_size = os.path.getsize(file_path) if os.path.isfile(file_path) else \"N/A\"\n",
        "            print(f\"  - {file} ({file_size} bytes)\" if file_size != \"N/A\" else f\"  - {file}\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå Path does not exist: {hf_path}\")\n",
        "\n",
        "# Create manual upload instructions\n",
        "if hf_path:\n",
        "    create_git_upload_instructions(hf_path, HF_MODEL_NAME)\n",
        "else:\n",
        "    print(\"‚ùå Cannot create upload instructions - model path not available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smk-Bcd4N9Zm"
      },
      "source": [
        "## 7. Model Usage Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i2eHjM-N9Zm"
      },
      "outputs": [],
      "source": [
        "# Model Usage Examples\n",
        "# ===================\n",
        "\n",
        "def create_usage_examples():\n",
        "    \"\"\"Create comprehensive usage examples with proper formatting\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üìö MODEL USAGE EXAMPLES\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    examples = f\"\"\"\n",
        "# Example 1: Basic Usage\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{HF_MODEL_NAME}\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"{HF_MODEL_NAME}\")\n",
        "\n",
        "# Example text\n",
        "text = \"The organic tea plantation tour was amazing! We learned about sustainable farming practices.\"\n",
        "\n",
        "# Tokenize and predict\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.sigmoid(outputs.logits)\n",
        "\n",
        "# Get predicted labels\n",
        "labels = {LABELS}\n",
        "predicted_labels = [labels[i] for i, score in enumerate(predictions[0]) if score > 0.5]\n",
        "print(f\"Predicted labels: {{predicted_labels}}\")\n",
        "\n",
        "# Example 2: Batch Processing\n",
        "texts = [\n",
        "    \"The spa retreat offered incredible yoga sessions and meditation classes.\",\n",
        "    \"The local cooking class was fantastic! We learned to make authentic Sri Lankan curry.\",\n",
        "    \"The hiking trail through the remote jungle was challenging but rewarding.\"\n",
        "]\n",
        "\n",
        "# Process multiple texts\n",
        "for text in texts:\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.sigmoid(outputs.logits)\n",
        "\n",
        "    predicted_labels = [labels[i] for i, score in enumerate(predictions[0]) if score > 0.5]\n",
        "    print(f\"Text: {{text[:50]}}...\")\n",
        "    print(f\"Labels: {{predicted_labels}}\")\n",
        "    print()\n",
        "\n",
        "# Example 3: Confidence Scores\n",
        "def get_confidence_scores(text, threshold=0.5):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.sigmoid(outputs.logits)\n",
        "\n",
        "    results = []\n",
        "    for i, (label, score) in enumerate(zip(labels, predictions[0])):\n",
        "        results.append({{\n",
        "            'label': label,\n",
        "            'score': float(score),\n",
        "            'predicted': score > threshold\n",
        "        }})\n",
        "\n",
        "    return results\n",
        "\n",
        "# Get detailed confidence scores\n",
        "text = \"The organic tea plantation tour was amazing! We learned about sustainable farming practices.\"\n",
        "scores = get_confidence_scores(text)\n",
        "for result in scores:\n",
        "    print(f\"{{result['label']}}: {{result['score']:.3f}} ({{'‚úì' if result['predicted'] else '‚úó'}})\")\n",
        "\n",
        "# Example 4: Production-ready Class\n",
        "class TourismClassifier:\n",
        "    def __init__(self, model_name=\"{HF_MODEL_NAME}\", threshold=0.5):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "        self.labels = {LABELS}\n",
        "        self.threshold = threshold\n",
        "        \n",
        "    def predict(self, text):\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            predictions = torch.sigmoid(outputs.logits)\n",
        "        \n",
        "        results = []\n",
        "        for i, (label, score) in enumerate(zip(self.labels, predictions[0])):\n",
        "            results.append({{\n",
        "                'label': label,\n",
        "                'score': float(score),\n",
        "                'predicted': score > self.threshold\n",
        "            }})\n",
        "        \n",
        "        return results\n",
        "\n",
        "# Usage\n",
        "classifier = TourismClassifier()\n",
        "result = classifier.predict(\"Amazing eco-friendly resort with organic food!\")\n",
        "print(result)\n",
        "\"\"\"\n",
        "\n",
        "    print(examples)\n",
        "\n",
        "# Display usage examples\n",
        "create_usage_examples()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF4d-DhMN9Zm"
      },
      "source": [
        "## 8. Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlRWUmFFN9Zm"
      },
      "outputs": [],
      "source": [
        "# Deployment Summary and Next Steps\n",
        "# =================================\n",
        "\n",
        "def deployment_summary():\n",
        "    \"\"\"Provide comprehensive deployment summary and next steps\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üéâ DEPLOYMENT SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Check deployment status\n",
        "    model_ready = hf_path and os.path.exists(hf_path)\n",
        "    config_ready = HF_MODEL_NAME != \"your-username/serendip-travel-classifier\"\n",
        "    hf_logged_in = hf_ready if 'hf_ready' in globals() else False\n",
        "\n",
        "    print(\"üìä Deployment Status:\")\n",
        "    print(f\"  {'‚úÖ' if model_ready else '‚ùå'} Model files prepared\")\n",
        "    print(f\"  {'‚úÖ' if config_ready else '‚ö†Ô∏è '} Model name configured\")\n",
        "    print(f\"  {'‚úÖ' if hf_logged_in else '‚ùå'} Hugging Face authentication\")\n",
        "\n",
        "    if model_ready:\n",
        "        print(f\"\\nüìÅ Model files saved to: {hf_path}\")\n",
        "        print(f\"üè∑Ô∏è  Model name: {HF_MODEL_NAME}\")\n",
        "        \n",
        "        # Get performance metrics from run_info if available\n",
        "        if 'run_info' in globals() and run_info:\n",
        "            metrics = run_info.data.metrics\n",
        "            f1_score = metrics.get('test_f1', 'N/A')\n",
        "            accuracy = metrics.get('test_accuracy', 'N/A')\n",
        "            print(f\"üìä Performance: {f1_score:.4f} F1-Score, {accuracy:.4f} Accuracy\")\n",
        "        else:\n",
        "            print(\"üìä Performance: 92.50% F1-Score, 92.33% Accuracy (from config)\")\n",
        "\n",
        "    print(\"\\nüìã Next Steps:\")\n",
        "    if not config_ready:\n",
        "        print(\"1. ‚ö†Ô∏è  Update HF_MODEL_NAME in configuration cell\")\n",
        "    if not hf_logged_in:\n",
        "        print(\"2. üîê Login to Hugging Face: huggingface-cli login\")\n",
        "    print(\"3. üöÄ Uncomment and run the upload function\")\n",
        "    print(\"4. üìù Update README.md with your actual model URL\")\n",
        "    print(\"5. üß™ Test the deployed model\")\n",
        "    print(\"6. üì¢ Share your model with the community!\")\n",
        "\n",
        "    if model_ready:\n",
        "        print(\"\\nüìÅ Files Created:\")\n",
        "        files = os.listdir(hf_path)\n",
        "        for file in files:\n",
        "            file_path = os.path.join(hf_path, file)\n",
        "            file_size = os.path.getsize(file_path) if os.path.isfile(file_path) else \"N/A\"\n",
        "            print(f\"  - {file} ({file_size} bytes)\" if file_size != \"N/A\" else f\"  - {file}\")\n",
        "\n",
        "    print(f\"\\nüîó Model will be available at:\")\n",
        "    print(f\"   https://huggingface.co/{HF_MODEL_NAME}\")\n",
        "\n",
        "    print(\"\\nüéØ Model Features:\")\n",
        "    print(\"  - Multi-label text classification\")\n",
        "    print(f\"  - {NUM_LABELS} experiential dimensions\")\n",
        "    print(f\"  - {MODEL_NAME} architecture\")\n",
        "    print(\"  - High performance (92%+ F1-Score)\")\n",
        "    print(\"  - Ready for production use\")\n",
        "\n",
        "    print(\"\\nüí° Usage Tips:\")\n",
        "    print(\"  - Use threshold 0.5 for binary predictions\")\n",
        "    print(\"  - Adjust threshold based on use case\")\n",
        "    print(\"  - Consider confidence scores for uncertainty\")\n",
        "    print(\"  - Batch processing for efficiency\")\n",
        "    print(\"  - Use the TourismClassifier class for production\")\n",
        "\n",
        "    print(\"\\nüîß Troubleshooting:\")\n",
        "    if not model_ready:\n",
        "        print(\"  - Check MLflow connection and run ID\")\n",
        "        print(\"  - Verify model download completed successfully\")\n",
        "    if not config_ready:\n",
        "        print(\"  - Update HF_MODEL_NAME in configuration\")\n",
        "    if not hf_logged_in:\n",
        "        print(\"  - Run: huggingface-cli login\")\n",
        "\n",
        "# Display summary\n",
        "deployment_summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZIesL5yN9Zm"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Deployment Checklist\n",
        "\n",
        "Use this checklist to ensure your model deployment is complete and ready for production:\n",
        "\n",
        "### Pre-Deployment\n",
        "- [ ] **Configuration**: Update `HF_MODEL_NAME` with your Hugging Face username\n",
        "- [ ] **Authentication**: Login to Hugging Face (`huggingface-cli login`)\n",
        "- [ ] **MLflow Access**: Verify MLflow connection and run ID\n",
        "- [ ] **Environment**: Confirm environment detection (Colab vs local)\n",
        "\n",
        "### Model Preparation\n",
        "- [ ] **Download**: Model successfully downloaded from MLflow\n",
        "- [ ] **Preparation**: Model converted to Hugging Face format\n",
        "- [ ] **Testing**: Model tested with sample texts\n",
        "- [ ] **Configuration**: `config.json` and `README.md` generated\n",
        "\n",
        "### Upload Process\n",
        "- [ ] **Repository**: Hugging Face repository created\n",
        "- [ ] **Upload**: All files uploaded successfully\n",
        "- [ ] **Verification**: Model accessible on Hugging Face Hub\n",
        "- [ ] **Documentation**: README displays correctly\n",
        "\n",
        "### Post-Deployment\n",
        "- [ ] **Testing**: Test deployed model with API\n",
        "- [ ] **Performance**: Verify model performance matches expectations\n",
        "- [ ] **Sharing**: Model is public and shareable\n",
        "- [ ] **Monitoring**: Set up usage monitoring (optional)\n",
        "\n",
        "### Production Readiness\n",
        "- [ ] **Code Examples**: Usage examples work correctly\n",
        "- [ ] **Error Handling**: Proper error handling in production code\n",
        "- [ ] **Documentation**: Complete model card and usage guide\n",
        "- [ ] **Version Control**: Model versioning strategy in place\n",
        "\n",
        "---\n",
        "\n",
        "**üéâ Congratulations!** Your model is now ready for production use on Hugging Face Hub.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx5sPAstN9Zm"
      },
      "source": [
        "## 9. Best Practices for Model File Management\n",
        "\n",
        "When working with ML models in a Git-based workflow, it's important to handle large model files correctly:\n",
        "\n",
        "### File Size Limitations\n",
        "- GitHub has a 100MB file size limit for individual files\n",
        "- PyTorch model files (`.pth`) often exceed this limit\n",
        "\n",
        "### Recommended Approaches\n",
        "\n",
        "1. **Use `.gitignore` for Local Model Files**\n",
        "   - This notebook downloads model artifacts to `.gitignore.d/` directories\n",
        "   - These directories are excluded from Git tracking\n",
        "   - Always check your `.gitignore` file includes: `*.pth`, `model_artifacts/`, `hf_model/`\n",
        "\n",
        "2. **Use Hugging Face Hub for Model Storage**\n",
        "   - Hugging Face Hub is designed for ML model storage\n",
        "   - This notebook includes all the code needed to push models to Hugging Face\n",
        "\n",
        "3. **Use Git LFS (optional)**\n",
        "   - For teams that need version control of model files\n",
        "   - Install Git LFS: `brew install git-lfs`\n",
        "   - Setup: `git lfs install && git lfs track \"*.pth\"`\n",
        "\n",
        "4. **MLflow for Experiment Tracking**\n",
        "   - Use MLflow to track experiments and store models\n",
        "   - Download models only when needed for deployment\n",
        "\n",
        "Remember: Always check what files are being added to Git before committing with `git status` to avoid accidentally committing large files."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "059159dfffb8454da5c85d9649a0b613": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac028af2cb6141898bd9b8947f809a52",
              "IPY_MODEL_fa919897ae544c0e90d5a0d1a39b0c57",
              "IPY_MODEL_7f49722f8afc4941a254bae3d09fa089"
            ],
            "layout": "IPY_MODEL_119fb99cf8ac4f7fb72e04ea80e16c55"
          }
        },
        "0666650edd274bd4845382e2cd840f59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c2a430228f14cb6978e78aad56283b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e52838fe9574d6e8eb9e9044a051dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "119fb99cf8ac4f7fb72e04ea80e16c55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122cb4ec9e2d4df7bb1d49fbbbb9938a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b89ef2c2ca5423a85782ccbd10269e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0666650edd274bd4845382e2cd840f59",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3089c4ea1a534a2ba8bd2d0d3156c8fa",
            "value": 0
          }
        },
        "1e05c92228e848eba05410138b8be299": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21539f3c4e814de49d514b1c8bd36111": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23dc88340108406c832e59946457e634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c7c460aea644e4ab9865f43b8b4d23c",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e05c92228e848eba05410138b8be299",
            "value": 6
          }
        },
        "3089c4ea1a534a2ba8bd2d0d3156c8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31b7994ee99b4bc18e7ec4ba4c525a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_608ed9edf9ee4f1cb59ccc473d3cabc6",
              "IPY_MODEL_23dc88340108406c832e59946457e634",
              "IPY_MODEL_3398b12db41f424b9a95cbdff93c6801"
            ],
            "layout": "IPY_MODEL_ec71b9b9644844ecb4283692037f9362"
          }
        },
        "320ded16b2d341a7a98bc4ef3c8409e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3398b12db41f424b9a95cbdff93c6801": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6395f67e16504e0d87873a115b472914",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5f92ab6d3b6447c2907316c6d9ceae56",
            "value": "‚Äá6/6‚Äá[00:29&lt;00:00,‚Äá‚Äá7.57s/it]"
          }
        },
        "36e9a01f4774408baa7cef8ee497cf95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f11fd66706e4845a9ea69b10402757e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497094dab6bd4b749563f033aa06af2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "530ef99640bc4cb6b3936a05efc18806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf547badfa7a4275a9c82c895cce723d",
              "IPY_MODEL_1b89ef2c2ca5423a85782ccbd10269e6",
              "IPY_MODEL_841d4f15e9d64f788e64d616558d312f"
            ],
            "layout": "IPY_MODEL_36e9a01f4774408baa7cef8ee497cf95"
          }
        },
        "578df85147bc40c3855fb6ede8efc242": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f92ab6d3b6447c2907316c6d9ceae56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "608ed9edf9ee4f1cb59ccc473d3cabc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7805b4cd8f414b22b144f967977056aa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_320ded16b2d341a7a98bc4ef3c8409e4",
            "value": "Downloading‚Äáartifacts:‚Äá100%"
          }
        },
        "6395f67e16504e0d87873a115b472914": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641fd6e02d86455c8aa36f42a7d3c57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6763d6b29bb2482eb14fdd078462f668": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7805b4cd8f414b22b144f967977056aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7898328708fa46118bd60a37d3fd21cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7903d848fb54474685d77d1a20717610": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79c18ad732224584ba3ec447c1476f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c86da99fa0cc421fb2467473beb33f99",
              "IPY_MODEL_b8e884518bab401c9991b8832563324d",
              "IPY_MODEL_b44cb092f84d4b9196f422d626240fa6"
            ],
            "layout": "IPY_MODEL_578df85147bc40c3855fb6ede8efc242"
          }
        },
        "7e29b7f4260d41e4919618519f4c19ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f49722f8afc4941a254bae3d09fa089": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e52838fe9574d6e8eb9e9044a051dc5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7e29b7f4260d41e4919618519f4c19ca",
            "value": "‚Äá6/6‚Äá[00:29&lt;00:00,‚Äá‚Äá7.65s/it]"
          }
        },
        "841d4f15e9d64f788e64d616558d312f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_122cb4ec9e2d4df7bb1d49fbbbb9938a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c5dc0fe4efc54ab79aba9ee9907aba9c",
            "value": "‚Äá0/1‚Äá[00:02&lt;?,‚Äá?it/s]"
          }
        },
        "8c7c460aea644e4ab9865f43b8b4d23c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ab8e339a92f4700a3ad6177863d46e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac028af2cb6141898bd9b8947f809a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21539f3c4e814de49d514b1c8bd36111",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_641fd6e02d86455c8aa36f42a7d3c57d",
            "value": "Downloading‚Äáartifacts:‚Äá100%"
          }
        },
        "b231df5bdece4fe195749704707811f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b44cb092f84d4b9196f422d626240fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7903d848fb54474685d77d1a20717610",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9ab8e339a92f4700a3ad6177863d46e2",
            "value": "‚Äá0/1‚Äá[00:02&lt;?,‚Äá?it/s]"
          }
        },
        "b8e884518bab401c9991b8832563324d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f11fd66706e4845a9ea69b10402757e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c2a430228f14cb6978e78aad56283b0",
            "value": 0
          }
        },
        "bf547badfa7a4275a9c82c895cce723d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db0b93c98cdb43afbd0d38fa4c60f8b6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_497094dab6bd4b749563f033aa06af2c",
            "value": "Downloading‚Äáartifacts:‚Äá‚Äá‚Äá0%"
          }
        },
        "c5dc0fe4efc54ab79aba9ee9907aba9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c86da99fa0cc421fb2467473beb33f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6763d6b29bb2482eb14fdd078462f668",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f9059503f2684e9986bcd452fe34c68f",
            "value": "Downloading‚Äáartifacts:‚Äá‚Äá‚Äá0%"
          }
        },
        "db0b93c98cdb43afbd0d38fa4c60f8b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec71b9b9644844ecb4283692037f9362": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9059503f2684e9986bcd452fe34c68f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa919897ae544c0e90d5a0d1a39b0c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b231df5bdece4fe195749704707811f8",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7898328708fa46118bd60a37d3fd21cf",
            "value": 6
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
