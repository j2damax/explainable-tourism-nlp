{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "66712107",
      "metadata": {
        "id": "66712107"
      },
      "source": [
        "# Model Training and Evaluation\n",
        "\n",
        "This notebook covers the definition, training, and evaluation of a transformer-based multi-label text classification model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a2b576",
      "metadata": {
        "id": "87a2b576"
      },
      "source": [
        "## 1. Load Prepared Datasets and Libraries\n",
        "\n",
        "Load the PyTorch datasets and import required libraries for model training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d49bc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "160ef9c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install databricks-sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ec1b6155",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec1b6155",
        "outputId": "5856f5ff-757f-4841-ecd2-9df4be3ab0cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0175ef35",
      "metadata": {
        "id": "0175ef35"
      },
      "outputs": [],
      "source": [
        "# Import libraries and load datasets\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "import numpy as np\n",
        "from mlflow.models import infer_signature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7fc08f98",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load environment variables from .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "25366548",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25366548",
        "outputId": "61d68e71-b748-4f32-b9bf-9c0efe244ff5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/3866477269740015', creation_time=1758424394648, experiment_id='3866477269740015', last_update_time=1758427431013, lifecycle_stage='active', name='/Users/j2damax@gmail.com/serendip-travel-review-classifier-experiments', tags={'mlflow.experiment.sourceName': '/Users/j2damax@gmail.com/serendip-travel-review-classifier-experiments',\n",
              " 'mlflow.experimentKind': 'genai_development',\n",
              " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
              " 'mlflow.ownerEmail': 'j2damax@gmail.com',\n",
              " 'mlflow.ownerId': '5804221812504751'}>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set Databricks credentials from environment variables (do not hardcode in code!)\n",
        "import os\n",
        "import mlflow\n",
        "DATABRICKS_HOST = os.getenv(\"DATABRICKS_HOST\")\n",
        "DATABRICKS_TOKEN = os.getenv(\"DATABRICKS_TOKEN\")\n",
        "if not DATABRICKS_HOST or not DATABRICKS_TOKEN:\n",
        "    raise ValueError(\"DATABRICKS_HOST and DATABRICKS_TOKEN must be set in your environment.\\n\\nIn Colab, use:\\n%env DATABRICKS_HOST=https://<your-databricks-instance>\\n%env DATABRICKS_TOKEN=<your-token>\\n\\nLocally, set them in your shell or .env file.\")\n",
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/j2damax@gmail.com/serendip-travel-review-classifier-experiments\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1000a64a",
      "metadata": {
        "id": "1000a64a"
      },
      "outputs": [],
      "source": [
        "# Define ReviewsDataset class (must match the one used in 03_modeling.ipynb)\n",
        "from torch.utils.data import Dataset\n",
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c29a52de",
      "metadata": {
        "id": "c29a52de"
      },
      "outputs": [],
      "source": [
        "#train_data = torch.load('../data/processed/train_dataset.pt', weights_only=False)\n",
        "#test_data = torch.load('../data/processed/test_dataset.pt', weights_only=False)\n",
        "\n",
        "# Load datasets from Google Drive\n",
        "train_data = torch.load('/content/drive/MyDrive/SerendipTravel/data/processed/train_dataset.pt', weights_only=False)\n",
        "test_data = torch.load('/content/drive/MyDrive/SerendipTravel/data/processed/test_dataset.pt', weights_only=False)\n",
        "\n",
        "# Reuse your ReviewsDataset class definition here\n",
        "train_dataset = ReviewsDataset(train_data['encodings'], train_data['labels'])\n",
        "test_dataset = ReviewsDataset(test_data['encodings'], test_data['labels'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "822f1aaf",
      "metadata": {
        "id": "822f1aaf"
      },
      "source": [
        "## 2. Model Definition and Configuration\n",
        "\n",
        "Define the transformer model for multi-label classification and set up optimizer, loss, and training parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1192ccd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1192ccd1",
        "outputId": "a68cf716-45d0-4014-8f20-84c747e241c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Model definition and configuration\n",
        "num_labels = train_data['labels'].shape[1]\n",
        "print(f\"Number of labels: {num_labels}\")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=num_labels,\n",
        "    problem_type='multi_label_classification'\n",
        ")\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 16\n",
        "epochs = 3\n",
        "learning_rate = 2e-5\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "# Loss function for multi-label\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fcdac3e",
      "metadata": {
        "id": "5fcdac3e"
      },
      "source": [
        "## 3. Model Training and Evaluation\n",
        "\n",
        "Train the model and evaluate its performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "dd0aceb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd0aceb3",
        "outputId": "a8a8f88d-c508-4667-c5bd-348cb8d9fa9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3 - Training loss: 0.0573\n",
            "Epoch 2/3 - Training loss: 0.0573\n",
            "Epoch 3/3 - Training loss: 0.0578\n",
            "Test accuracy: 0.9245049504950495\n",
            "Test macro F1: 0.9298934093407507\n",
            "ðŸƒ View run bert-multilabel-baseline at: https://dbc-cfeb31c8-2841.cloud.databricks.com/ml/experiments/3866477269740015/runs/5728587524314f69b56434d8d58e9490\n",
            "ðŸ§ª View experiment at: https://dbc-cfeb31c8-2841.cloud.databricks.com/ml/experiments/3866477269740015\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluation loop with MLflow logging\n",
        "import mlflow.pytorch\n",
        "with mlflow.start_run(run_name=\"bert-multilabel-baseline\"):\n",
        "    # Log hyperparameters\n",
        "    mlflow.log_param(\"epochs\", epochs)\n",
        "    mlflow.log_param(\"batch_size\", batch_size)\n",
        "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
        "    mlflow.log_param(\"model_name\", \"bert-base-uncased\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Training loss: {avg_train_loss:.4f}\")\n",
        "        mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].cpu().numpy()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits.cpu().numpy()\n",
        "            preds = (torch.sigmoid(torch.tensor(logits)) > 0.5).int().numpy()\n",
        "            all_preds.append(preds)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    import numpy as np\n",
        "    all_preds = np.vstack(all_preds)\n",
        "    all_labels = np.vstack(all_labels)\n",
        "\n",
        "    # Compute metrics\n",
        "    from sklearn.metrics import accuracy_score, f1_score\n",
        "    test_accuracy = accuracy_score(all_labels, all_preds)\n",
        "    test_macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    print(\"Test accuracy:\", test_accuracy)\n",
        "    print(\"Test macro F1:\", test_macro_f1)\n",
        "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
        "    mlflow.log_metric(\"test_macro_f1\", test_macro_f1)\n",
        "\n",
        "    # Prepare a sample input and output\n",
        "    example_batch = next(iter(test_loader))\n",
        "    inputs = {\n",
        "        \"input_ids\": example_batch[\"input_ids\"][:1].cpu().numpy(),\n",
        "        \"attention_mask\": example_batch[\"attention_mask\"][:1].cpu().numpy()\n",
        "    }\n",
        "    outputs = model(\n",
        "        input_ids=example_batch[\"input_ids\"][:1].to(device),\n",
        "        attention_mask=example_batch[\"attention_mask\"][:1].to(device)\n",
        "    ).logits.cpu().detach().numpy()\n",
        "\n",
        "    signature = infer_signature(inputs, outputs)\n",
        "\n",
        "    mlflow.pytorch.log_model(\n",
        "        model,\n",
        "        name=\"model\",\n",
        "        signature=signature,\n",
        "        pip_requirements=[\"torch==2.8.0+cu126\", \"torchvision==0.23.0+cu126\"]\n",
        "    )\n",
        "\n",
        "    np.save(\"predictions.npy\", all_preds)\n",
        "    mlflow.log_artifact(\"predictions.npy\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.4)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
