import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import streamlit.components.v1 as components
import json

# Import our modules
fr                        # Display word impact visualization using HTML
                        shap_html = result["explanation"]["html"]
                        
                        # Directly render the HTML content with full width and sufficient height
                        st.subheader("Word Impact on Prediction")
                        
                        # Add a container with styling to ensure the visualization is properly sized
                        with st.container():
                            st.markdown("""
                            <style>
                            .shap-container {
                                width: 100%;
                                overflow-x: hidden;
                                padding: 10px;
                            }
                            .shap-container img {
                                width: 100%;
                            }
                            </style>
                            """, unsafe_allow_html=True)
                            
                            # Use a larger height and disable scrolling for better viewing
                            components.html(f'<div class="shap-container">{shap_html}</div>', height=500, scrolling=False)
                            
                        # Add some explanation about how to interpret the visualizationg import UI_CONFIG, API_CONFIG, DIMENSIONS, SAMPLE_REVIEWS, SCORE_THRESHOLDS
from api_service import check_health, get_dimensions, analyze_review

# Import GenAI benchmark module
try:
    from genai_module import run_genai_benchmark, compare_results
    GENAI_AVAILABLE = UI_CONFIG["genai_enabled"]
except ImportError:
    GENAI_AVAILABLE = False

# Set page config
st.set_page_config(
    page_title=UI_CONFIG["page_title"],
    page_icon=UI_CONFIG["page_icon"],
    layout=UI_CONFIG["layout"],
    initial_sidebar_state=UI_CONFIG["initial_sidebar_state"],
)

# Load custom CSS
with open('styles.css') as f:
    st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

# Check API health at startup
api_status = check_health()
if not api_status["available"]:
    st.warning("‚ö†Ô∏è Backend API not available. Some features may not work correctly.")
elif not api_status["model_loaded"]:
    st.info("‚ÑπÔ∏è Model is still loading. First analysis may take longer than usual.")

# App header
st.markdown('<div class="main-header">Serendip Experiential Engine</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">Analyze Sri Lankan Tourism Experiences</div>', unsafe_allow_html=True)

description = "This application analyzes tourism reviews to identify key experiential dimensions in Sri Lankan tourism:"
for dim in DIMENSIONS:
    description += f"\n* {dim['icon']} **{dim['name']}**: {dim['description']}"

st.markdown(description)

# Sidebar
st.sidebar.image(UI_CONFIG["logo_url"], use_container_width=True)
st.sidebar.markdown("## About")
st.sidebar.info(
    "Serendip Experiential Engine uses NLP and explainable AI to help tourism "
    "stakeholders understand visitor experiences and preferences through advanced text analytics."
)

# Note: These functions are now imported from api_service.py

# Main application logic
with st.container():
    st.markdown("## üìù Enter a Tourism Review")
    
    # Sample reviews from config
    
    sample_select = st.selectbox("Try a sample review or write your own:", 
                                ["Write my own"] + SAMPLE_REVIEWS)
    
    if sample_select == "Write my own":
        review_text = st.text_area("Enter your review:", 
                                  height=150,
                                  placeholder="Describe your tourism experience in Sri Lanka...")
    else:
        review_text = sample_select
        st.text_area("Review text:", sample_select, height=150)
    
    # Initialize session state for caching
    if 'analysis_cache' not in st.session_state:
        st.session_state.analysis_cache = {}
    
    # Analyze button
    if st.button("Analyze Experience Dimensions", type="primary"):
        if not review_text:
            st.warning("Please enter a review to analyze.")
        else:
            # Check cache first
            if review_text in st.session_state.analysis_cache:
                result = st.session_state.analysis_cache[review_text]
                st.success("Analysis retrieved from cache!")
            else:
                with st.spinner('Analyzing review...'):
                    # Call backend API
                    result = analyze_review(review_text)
                    
                    # Cache the result if successful
                    if result:
                        st.session_state.analysis_cache[review_text] = result
            
            if result:
                    st.success("Analysis complete!")
                    
                    # Display results
                    st.markdown("## üìä Experience Dimension Analysis")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # Create a bar chart of dimension scores
                        dimensions = list(result["predictions"].keys())
                        scores = list(result["predictions"].values())
                        
                        # Convert scores to percentages
                        scores_pct = [round(score * 100, 1) for score in scores]
                        
                        # Create dataframe for plotting
                        df_scores = pd.DataFrame({
                            'Dimension': dimensions,
                            'Score': scores_pct
                        })
                        
                        fig = px.bar(
                            df_scores,
                            y='Dimension',
                            x='Score',
                            orientation='h',
                            color='Score',
                            color_continuous_scale='Viridis',
                            labels={'Score': 'Confidence Score (%)'},
                            title='Experience Dimension Confidence Scores'
                        )
                        
                        fig.update_layout(
                            height=400, 
                            yaxis={'categoryorder':'total ascending'}
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        st.markdown("### Key Influencing Factors")
                        st.info("These words and phrases most strongly influenced the classification:")
                        
                        # Show the top dimension
                        top_dim = max(result["predictions"].items(), key=lambda x: x[1])[0]
                        
                        st.markdown(f"#### Top Dimension: {top_dim}")
                        
                        if "explanation" in result and "top_words" in result["explanation"] and top_dim in result["explanation"]["top_words"]:
                            # Create table of top words and their importance
                            words = [item["word"] for item in result["explanation"]["top_words"][top_dim]]
                            values = [round(item["value"] * 100, 1) for item in result["explanation"]["top_words"][top_dim]]
                            is_positive = [item.get("is_positive", True) for item in result["explanation"]["top_words"][top_dim]]
                            
                            df_words = pd.DataFrame({
                                'Word': words,
                                'Importance': values,
                                'Impact': ['Positive' if pos else 'Negative' for pos in is_positive]
                            })
                            
                            st.dataframe(
                                df_words.sort_values(by='Importance', ascending=False),
                                hide_index=True,
                                use_container_width=True
                            )
                        else:
                            st.write("Explanation data not available")
                    
                    # SHAP Visualization Section
                    st.markdown("## üîç Explainable AI Visualization")
                    st.markdown("### SHAP Force Plot")
                    st.info("This visualization shows how each word contributes to the prediction for each dimension.")
                    
                    if "explanation" in result and "html" in result["explanation"]:
                        # Display word impact visualization using HTML
                        shap_html = result["explanation"]["html"]
                        
                        # Directly render the HTML content with improved styling
                        st.subheader("Word Impact on Prediction")
                        
                        # Add custom CSS to make the visualization larger and more visible
                        st.markdown("""
                        <style>
                        .shap-container {
                            width: 100%;
                            overflow-x: hidden;
                            padding: 10px;
                        }
                        .shap-container img {
                            width: 100%;
                            max-height: none !important;
                        }
                        </style>
                        """, unsafe_allow_html=True)
                        
                        # Use a larger height and disable scrolling for better viewing
                        components.html(f'<div class="shap-container">{shap_html}</div>', height=500, scrolling=False)
                            
                        # Add some explanation about how to interpret the visualization
                        st.caption("**How to interpret:** Red words push the prediction higher, blue words push it lower. The width of the bar indicates the magnitude of the impact.")
                    else:
                        st.warning("SHAP visualization data not available.")
                    
                    # GenAI Comparison Section
                    st.markdown("## ü§ñ GenAI vs BERT Comparison")
                    
                    if GENAI_AVAILABLE:
                        with st.spinner("Running GPT-4 few-shot classification..."):
                            try:
                                # Run GenAI benchmark
                                genai_results = run_genai_benchmark(review_text)
                                
                                # Compare with BERT results
                                comparison = compare_results(result["predictions"], genai_results)
                                
                                # Show results
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.markdown("### BERT Classification")
                                    # Convert scores to categories for easier comparison
                                    bert_categories = {}
                                    for dim, score in result["predictions"].items():
                                        if score > SCORE_THRESHOLDS["high"]:
                                            category = "HIGH"
                                        elif score > SCORE_THRESHOLDS["medium"]:
                                            category = "MEDIUM"
                                        else:
                                            category = "LOW"
                                        bert_categories[dim] = category
                                    
                                    # Create dataframe
                                    bert_df = pd.DataFrame({
                                        "Dimension": list(result["predictions"].keys()),
                                        "Score": [f"{round(score * 100)}%" for score in result["predictions"].values()],
                                        "Category": list(bert_categories.values())
                                    })
                                    st.dataframe(bert_df, hide_index=True, use_container_width=True)
                                
                                with col2:
                                    st.markdown("### GenAI Classification (GPT-4)")
                                    # Skip metadata and error keys
                                    genai_dims = {k: v for k, v in genai_results.items() 
                                                if k not in ["metadata", "error"]}
                                    
                                    # Create dataframe
                                    genai_df = pd.DataFrame({
                                        "Dimension": list(genai_dims.keys()),
                                        "Category": list(genai_dims.values())
                                    })
                                    st.dataframe(genai_df, hide_index=True, use_container_width=True)
                                
                                # Agreement metrics
                                agreement = comparison["agreement_percentage"]
                                st.metric("Model Agreement", f"{round(agreement)}%", 
                                         delta=None)
                                
                                # Comparison table
                                st.markdown("### üìä Model Comparison")
                                
                                comp_data = {
                                    "Metric": [
                                        "Inference Time", 
                                        "Cost per 1K Reviews", 
                                        "Reproducibility",
                                        "Explainability",
                                        "Customizability"
                                    ],
                                    "BERT": [
                                        comparison["cost_comparison"]["bert"]["inference_time"],
                                        comparison["cost_comparison"]["bert"]["cost_per_1k_reviews"],
                                        comparison["cost_comparison"]["bert"]["reproducibility"],
                                        "High (SHAP visualization)",
                                        "High (can fine-tune on custom data)"
                                    ],
                                    "GenAI (GPT-4)": [
                                        comparison["cost_comparison"]["genai"]["inference_time"],
                                        comparison["cost_comparison"]["genai"]["cost_per_1k_reviews"],
                                        comparison["cost_comparison"]["genai"]["reproducibility"],
                                        "Medium (rationale but no word-level)",
                                        "Medium (prompt engineering)"
                                    ]
                                }
                                
                                comp_df = pd.DataFrame(comp_data)
                                st.dataframe(comp_df, hide_index=True, use_container_width=True)
                                
                                # Tokens used
                                st.caption(f"GPT-4 tokens used: {genai_results.get('metadata', {}).get('tokens_used', 'N/A')}")
                                
                            except Exception as e:
                                st.error(f"Error in GenAI comparison: {str(e)}")
                    else:
                        st.warning("GenAI comparison not available. Make sure you have the OpenAI API key set in the environment.")

# Footer
st.markdown("---")
st.markdown('<div class="info-text">Serendip Experiential Engine | Powered by Explainable AI</div>', unsafe_allow_html=True)