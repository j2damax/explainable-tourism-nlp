{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e328aa5",
   "metadata": {},
   "source": [
    "# Multi-Label Text Classification: Modeling with Transformers\n",
    "\n",
    "This notebook covers the modeling workflow for multi-label text classification using transformer models. We will load the processed data, perform train/test split, tokenize the text, and prepare the data for modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5ef5e",
   "metadata": {},
   "source": [
    "## 1. Load the Processed Data\n",
    "\n",
    "Load the pre-processed dataset from disk using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aabe686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_Name</th>\n",
       "      <th>Located_City</th>\n",
       "      <th>Location</th>\n",
       "      <th>Location_Type</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>User_Location</th>\n",
       "      <th>User_Locale</th>\n",
       "      <th>User_Contributions</th>\n",
       "      <th>Travel_Date</th>\n",
       "      <th>Published_Date</th>\n",
       "      <th>...</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>Regenerative &amp; Eco-Tourism_keyword_count</th>\n",
       "      <th>Integrated Wellness_keyword_count</th>\n",
       "      <th>Immersive Culinary_keyword_count</th>\n",
       "      <th>Off-the-Beaten-Path Adventure_keyword_count</th>\n",
       "      <th>label_regenerative_eco_tourism</th>\n",
       "      <th>label_integrated_wellness</th>\n",
       "      <th>label_immersive_culinary</th>\n",
       "      <th>label_off_the_beaten_path_adventure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arugam Bay</td>\n",
       "      <td>Arugam Bay</td>\n",
       "      <td>Arugam Bay, Eastern Province</td>\n",
       "      <td>Beaches</td>\n",
       "      <td>User 1</td>\n",
       "      <td>Dunsborough, Australia</td>\n",
       "      <td>en_US</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-31T07:53:21-04:00</td>\n",
       "      <td>...</td>\n",
       "      <td>i had a manicure here and it really was profes...</td>\n",
       "      <td>best nail spa in arugam bay on the water!</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arugam Bay</td>\n",
       "      <td>Arugam Bay</td>\n",
       "      <td>Arugam Bay, Eastern Province</td>\n",
       "      <td>Beaches</td>\n",
       "      <td>User 2</td>\n",
       "      <td>Bendigo, Australia</td>\n",
       "      <td>en_US</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-06</td>\n",
       "      <td>2019-07-21T21:50:11-04:00</td>\n",
       "      <td>...</td>\n",
       "      <td>overall, it is a wonderful experience. we visi...</td>\n",
       "      <td>best for surfing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arugam Bay</td>\n",
       "      <td>Arugam Bay</td>\n",
       "      <td>Arugam Bay, Eastern Province</td>\n",
       "      <td>Beaches</td>\n",
       "      <td>User 3</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>en_US</td>\n",
       "      <td>13</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-15T18:52:55-04:00</td>\n",
       "      <td>...</td>\n",
       "      <td>great place to chill, swim, surf, eat, shop, h...</td>\n",
       "      <td>we love arugam bay</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arugam Bay</td>\n",
       "      <td>Arugam Bay</td>\n",
       "      <td>Arugam Bay, Eastern Province</td>\n",
       "      <td>Beaches</td>\n",
       "      <td>User 4</td>\n",
       "      <td>Ericeira, Portugal</td>\n",
       "      <td>en_US</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-06</td>\n",
       "      <td>2019-07-03T10:32:41-04:00</td>\n",
       "      <td>...</td>\n",
       "      <td>good place for surf and a few stores to going ...</td>\n",
       "      <td>sun and waves.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arugam Bay</td>\n",
       "      <td>Arugam Bay</td>\n",
       "      <td>Arugam Bay, Eastern Province</td>\n",
       "      <td>Beaches</td>\n",
       "      <td>User 5</td>\n",
       "      <td>Pistoia, Italy</td>\n",
       "      <td>en_US</td>\n",
       "      <td>14</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-02T17:07:02-04:00</td>\n",
       "      <td>...</td>\n",
       "      <td>this place is great for surfing but even if yo...</td>\n",
       "      <td>great swimming, surfing, great fish aznd frien...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location_Name Located_City                      Location Location_Type  \\\n",
       "0    Arugam Bay   Arugam Bay  Arugam Bay, Eastern Province       Beaches   \n",
       "1    Arugam Bay   Arugam Bay  Arugam Bay, Eastern Province       Beaches   \n",
       "2    Arugam Bay   Arugam Bay  Arugam Bay, Eastern Province       Beaches   \n",
       "3    Arugam Bay   Arugam Bay  Arugam Bay, Eastern Province       Beaches   \n",
       "4    Arugam Bay   Arugam Bay  Arugam Bay, Eastern Province       Beaches   \n",
       "\n",
       "  User_ID           User_Location User_Locale  User_Contributions Travel_Date  \\\n",
       "0  User 1  Dunsborough, Australia       en_US                   8     2019-07   \n",
       "1  User 2      Bendigo, Australia       en_US                   4     2019-06   \n",
       "2  User 3    Melbourne, Australia       en_US                  13     2019-07   \n",
       "3  User 4      Ericeira, Portugal       en_US                   4     2019-06   \n",
       "4  User 5          Pistoia, Italy       en_US                  14     2019-07   \n",
       "\n",
       "              Published_Date  ...  \\\n",
       "0  2019-07-31T07:53:21-04:00  ...   \n",
       "1  2019-07-21T21:50:11-04:00  ...   \n",
       "2  2019-07-15T18:52:55-04:00  ...   \n",
       "3  2019-07-03T10:32:41-04:00  ...   \n",
       "4  2019-07-02T17:07:02-04:00  ...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  i had a manicure here and it really was profes...   \n",
       "1  overall, it is a wonderful experience. we visi...   \n",
       "2  great place to chill, swim, surf, eat, shop, h...   \n",
       "3  good place for surf and a few stores to going ...   \n",
       "4  this place is great for surfing but even if yo...   \n",
       "\n",
       "                                         clean_title  \\\n",
       "0          best nail spa in arugam bay on the water!   \n",
       "1                                   best for surfing   \n",
       "2                                 we love arugam bay   \n",
       "3                                     sun and waves.   \n",
       "4  great swimming, surfing, great fish aznd frien...   \n",
       "\n",
       "  Regenerative & Eco-Tourism_keyword_count Integrated Wellness_keyword_count  \\\n",
       "0                                        1                                 2   \n",
       "1                                        0                                 0   \n",
       "2                                        1                                 0   \n",
       "3                                        0                                 0   \n",
       "4                                        1                                 0   \n",
       "\n",
       "  Immersive Culinary_keyword_count  \\\n",
       "0                                0   \n",
       "1                                1   \n",
       "2                                0   \n",
       "3                                0   \n",
       "4                                1   \n",
       "\n",
       "  Off-the-Beaten-Path Adventure_keyword_count  label_regenerative_eco_tourism  \\\n",
       "0                                           0                               1   \n",
       "1                                           0                               0   \n",
       "2                                           0                               1   \n",
       "3                                           0                               0   \n",
       "4                                           0                               1   \n",
       "\n",
       "   label_integrated_wellness  label_immersive_culinary  \\\n",
       "0                          1                         0   \n",
       "1                          0                         1   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         1   \n",
       "\n",
       "   label_off_the_beaten_path_adventure  \n",
       "0                                    0  \n",
       "1                                    0  \n",
       "2                                    0  \n",
       "3                                    0  \n",
       "4                                    0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load processed data\n",
    "import pandas as pd\n",
    "\n",
    "# Choose one: CSV or pickle (pickle preserves dtypes)\n",
    "df = pd.read_pickle('../data/processed/tourism_reviews_processed.pkl')\n",
    "# df = pd.read_csv('../data/processed/tourism_reviews_processed.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d779f93b",
   "metadata": {},
   "source": [
    "## 2. Perform Train/Test Split\n",
    "\n",
    "Split the loaded data into training and testing sets using scikit-learn's train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f20efb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 12924, Test size: 3232\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define text and label columns\n",
    "text_col = 'clean_text'\n",
    "label_cols = [col for col in df.columns if col.startswith('label_')]\n",
    "\n",
    "X = df[text_col].values\n",
    "Y = df[label_cols].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42, stratify=Y\n",
    ")\n",
    "\n",
    "print(f'Train size: {len(X_train)}, Test size: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821ec5d",
   "metadata": {},
   "source": [
    "## 3. Tokenize for Transformers\n",
    "\n",
    "Use a Hugging Face tokenizer (BertTokenizer) to tokenize the text data for transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25d4b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n",
      "Train encodings: torch.Size([12924, 128])\n",
      "Test encodings: torch.Size([3232, 128])\n"
     ]
    }
   ],
   "source": [
    "# Tokenization for transformers\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize train and test text\n",
    "def tokenize_texts(texts, tokenizer, max_length=128):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_texts(X_train, tokenizer)\n",
    "test_encodings = tokenize_texts(X_test, tokenizer)\n",
    "\n",
    "print('Tokenization complete.')\n",
    "print(f\"Train encodings: {train_encodings['input_ids'].shape}\")\n",
    "print(f\"Test encodings: {test_encodings['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e7eb9",
   "metadata": {},
   "source": [
    "## 4. Prepare Data for Modeling\n",
    "\n",
    "Convert tokenized data and labels into a PyTorch Dataset for use with transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53773cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 12924\n",
      "Test dataset size: 3232\n"
     ]
    }
   ],
   "source": [
    "# Prepare PyTorch Dataset for modeling\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ReviewsDataset(train_encodings, Y_train)\n",
    "test_dataset = ReviewsDataset(test_encodings, Y_test)\n",
    "\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Test dataset size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff6cb16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train and test encodings/labels for later use.\n"
     ]
    }
   ],
   "source": [
    "# Save only encodings and labels for reproducibility and compatibility\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "torch.save({'encodings': train_encodings, 'labels': Y_train}, '../data/processed/train_dataset.pt')\n",
    "torch.save({'encodings': test_encodings, 'labels': Y_test}, '../data/processed/test_dataset.pt')\n",
    "print('Saved train and test encodings/labels for later use.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
